[[monitor-kubernetes]]
= Monitor Kubernetes: Observe the health and performance of your Kubernetes deployments

TODO: Remove the following list along with all author names before publishing. 

*Assumptions made during content development:*

* Users are familiar with Kubernetes concepts.
* We will publish this content in phases. The first phase will include the
monitoring overview plus sections about monitoring K8s logs and metrics.
* We may provide a sample application to complement this guide.
* We will update this guide to use Elastic Agent + integrations when Fleet is
GA.

[discrete]
== What you’ll learn

[Author: DeDe]

In this guide, you’ll learn how to use the {stack} to collect, analyze, and
correlate logs and metrics from containers, applications, and services
running on top of Kubernetes.

This guide describes how to deploy Elastic monitoring agents as DaemonSets.
For other deployment options, see:

* {eck-ref}/index.html[{ecloud} on Kubernetes (ECK)]
* https://github.com/elastic/helm-charts/blob/master/README.md[Helm charts]

[discrete]
== Before you begin

[Author: DeDe]

TODO: List the prerequisites here. For example, {es} for storing and searching
your data, and {kib} for visualizing and managing it, Kubernetes config that's
required, like setting up Kubernetes to generate logs, enable
kube-state-metrics, etc.

[discrete]
== Monitoring overview

[Author: DeDe]

TODO: Provide an introduction to Kubernetes monitoring. Some things we might
want to cover:

* Describe challenges of monitoring a complex, distributed, transient system -
monitoring multiple layers (host system, applications, container, orchestration
software itself). Containers are a moving target, etc. These blog posts have
some good introductory info:
https://www.elastic.co/blog/kubernetes-observability-tutorial-k8s-log-monitoring-and-analysis-elastic-stack[here]
and https://www.elastic.co/blog/monitoring-kubernetes-and-docker-containers-with-beats-logs-metrics-and-metadata[here].

* Provide an overview of monitoring capabilities, perhaps with a diagram. Might
want to show an example deployment that’s running a couple of applications, like
Nginx and MySQL. Describe the data to collect and the technology stack for
collecting the data. Probably best to keep this as a broad overview and explore
the finer details later, but should touch on these concepts:

** Deployment: What is a DaemonSet? Why deploy as a DaemonSet?

** Filebeat for log collection

** Metricbeat for metrics collection

** Metadata for correlating logs, metrics, and traces:
add_cloud_metada, add_docker_metada, add_kubernetes_metadata

** Autodiscovery for automatically detecting and monitoring services as they appear
dynamically. To avoid too much front loading, probably shouldn't talk about
details like hints-based autodiscovery, labels, and templates, but will need to
cover that some later.


[discrete]
== Part 1: Monitor logs

[Author: TBD]

TODO: Provide a brief intro. We'll need to decide how much to cover here vs
the monitoring overview. Again lots of good introductory info here:
https://www.elastic.co/blog/kubernetes-observability-tutorial-k8s-log-monitoring-and-analysis-elastic-stack)

[discrete]
=== Logs you should monitor

TODO: Discuss the various logs (Kubernetes cluster, nodes, host, container logs)
that users might want to collect. I'm not sure if this deserves a separate
section or should be part of the previous section.

[discrete]
=== Deploy {filebeat} to collect logs

TODO: Describe how to configure and deploy Filebeat as a daemonset. We should
walk users through the parts of the deployment YAMLs, explain what they do, and point
out the settings they might want to change or add. Rough list of what
we need to cover:

* Download the Filebeat deployment manifest

* Set the connection information for Elasticsearch (also describe how to create
secrets)

* Configure log collection:

** Collect Kubernetes logs (cluster, node)

** Collect host logs

** Collect container logs (use autodiscovery)
We should probably explain what the default config with the container input does
then focus on documenting how to use autodiscovery. 

* Add metadata to events. Enrich the event with metadata coming from Docker,
Kubernetes, host, and the cloud providers.

* (optional) Drop unwanted events

* Deploy Filebeat as a DaemonSet on Kubernetes

[discrete]
=== View logs in {kib}

TODO: Describe how to view logs in Kibana. Show how to use the Logs app and how to
set up and view pre-built dashboards and visualizations.

[discrete]
== Part 2: Monitor health and performance metrics

[Author: TBD]

TODO: provide a brief intro. We'll need to figure out how much to cover here vs
the monitoring overview. Again lots of good introductory info under
"K8s metrics collection with Metricbeat"
https://www.elastic.co/blog/kubernetes-observability-tutorial-k8s-metrics-collection-and-analysis[here].


[discrete]
=== Metrics you should monitor

TODO: Discuss the metrics that users should monitor: cluster-level
metrics from Kubernetes, pod metrics, metrics about nodes, technology-specific
metrics (like nginx),etc. Explain where the metrics come from (kubelet API,kube-state-metrics,
apiserver, etc) and why to monitor them.


[discrete]
=== Deploy {metricbeat} to collect metrics

TODO: Describe how to configure and deploy Metricbeat as a daemonset. Rough list
of what we need to cover:

* Download the Metricbeat deployment manifest

* Set the connection information for Elasticsearch (also describe how to create
secrets or point to earlier section for reminder)

* Configure metrics collection:

** Collect system metrics.

** Collect Docker metrics.

** Collect Kubernetes pod metrics.

** Collect Kubernetes state metrics

** Collect application-specific metrics (use hint-based autodiscovery).
Examples: NGINX, MySQL

** Collect metrics from Prometheus.

* Add metadata to events. Describe how the events are enriched with
metadata coming from Docker, Kubernetes, host, and the cloud providers

* Deploy Metricbeat as a DaemonSet on Kubernetes

[discrete]
=== View performance and health metrics

TODO: Describe how to use the Metrics app and pre-built dashboards/visualizations.

[discrete]
== Part 3: Monitor uptime and availability data

[Author: TBD]

TODO: provide a brief intro.

[discrete]
=== Deploy {heartbeat} to collect uptime and availability data

TODO: Describe how to configure and deploy Heartbeat as a daemonset.

[discrete]
=== View uptime and availability in {kib}

TODO: Describe how to use the Uptime app and pre-built dashboards/visualizations.

[discrete]
== Part 4: Monitor internal network traffic data

[Author: TBD]

TODO: provide a brief intro.

[discrete]
=== Deploy {packetbeat} to capture network traffic data

TODO: Describe how to configure and deploy Packetbeat as a daemonset.

[discrete]
=== View network traffic data

TODO: Describe how to use the pre-built dashboards/visualizations.

[discrete]
== Part 5: Monitor application performance

[Author: Eyal]

TODO: Describe how to use APM to monitor applications.

[discrete]
=== Set up APM Server

TODO: Describe how to set up APM server.

[discrete]
==== Through ECK

Question: Are we sure we want to cover ECK here? Can we point to the ECK docs
instead? If we try to document all the ways in all the sections, I think users
might get confused.

[discrete]
==== On cloud

TODO: Describe how to set up APM server on cloud.

[discrete]
==== Download and install

TODO: Describe how to download and install APM server from archives.

[discrete]
=== Set up APM Agents

TODO: Describe how to set up the agents:

Question: Can we show the setup for one type of agent, then point to related
docs for other agents?

* Java agent (see https://www.elastic.co/blog/using-elastic-apm-java-agent-on-kubernetes-k8s)
* NodeJS Agent
* Python Agent
* ... and so forth


[discrete]
=== Configure

TODO: Describe how to add Kubernetes data to events by adding environment
variables to the K8s pod spec.

Question: Is there a more descriptive title that we can use for this section?
"Configure" seems a bit vague. By reading the docs, it sounds like you sometimes
need to add these variables, but it's not clear when/why you add them.


[discrete]
== Part 6: Diagnose bottlenecks and other issues

[Author: TBD? PM?]

TODO: Describe how to explore a real problem by navigating
observability UIs and dashboards. This section should showcase the power of
using our observability solution (being able to correlate logs, metrics, and
traces to solve a specific, real-world problem). The section title needs to
match whatever scenario we decide to discuss.

[discrete]
== What’s next

[Author: DeDe]

TODO: Add links to related topics that users might want to explore, such as
anomoly detection. 


