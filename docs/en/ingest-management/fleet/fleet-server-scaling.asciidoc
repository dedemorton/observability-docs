[discrete]
[[fleet-server-scalability]]
== {fleet-server} scalability

This section summarizes the resource and {fleet-server} configuration
requirements needed to scale your deployment of {agent}s. To scale
{fleet-server}, you need to modify settings in your deployment and the
{fleet-server} agent policy.

First modify your {fleet} deployment settings in {ecloud}:

. Log in to {ecloud} and go to your deployment.

. Under *Deployments > _deployment name_*, click *Edit*.

. Under APM & Fleet:
+
--
* Modify the compute resources available to the server to accommodate a higher
scale of {agent}s
* Modify the availability zones to satisfy fault tolerance requirements

For recommended settings, refer to <<scaling-recommendations>>.

[role="screenshot"]
image::images/fleet-server-hosted-container.png[{fleet-server} hosted agent]
--

Next modify the {fleet-server} configuration by editing the agent policy: 

. In *Fleet*, click *Agent Policies*. Click on the *{ecloud} agent policy* to
edit it.

. Open the *Actions* menu and select *Edit integration*.
+
[role="screenshot"]
image::images/elastic-cloud-agent-policy.png[{ecloud} policy]

. Under {fleet-server}, modify *Max Connections* and other
<<fleet-server-configuration,advanced settings>> as described in
<<scaling-recommendations>>. 
+
[role="screenshot"]
image::images/fleet-server-configuration.png[{fleet-server} configuration]

[discrete]
[[fleet-server-configuration]]
=== Advanced {fleet-server} options

The following advanced settings are available to fine tune your {fleet-server}
deployment.

//TODO: We need to discuss the best way to format config settings. I'm using
//mostly tables in other sections of the docs for improved scanning, but that is
//controversial.

//Nima: I tried removed repetitive words and tried clarify the descriptions here,
//but there were some inconsistencies. You'll want to check this carefully.

`cache`::

`num_counters`:::
Size of the hash table. Best practice is to have this set to 10x max
connections.

`max_cost`:::
Total size of the cache.

`server.limits`::
`policy_throttle`:::
How often a new policy is rolled out to the agents.

`checkin_limit.interval`:::
How fast the agents can check in to the {fleet-server}.

`checkin_limit.burst`:::
Burst of check-ins allowed before falling back to the rate defined by
`interval`.

`checkin_limit.max`:::
Maximum number of agents.

`artifact_limit.max`:::
Maximum number of agents that can call the artifact API concurrently. It allows
the user to avoid overloading the {fleet-server} from artifact API calls.

`artifact_limit.interval`:::
How often artifacts are rolled out. Default of 100ms allows 10 artifacts to be
rolled out per second.

`artifact_limit.burst`:::
Number of transactions allowed for a burst, controlling oversubscription on
outbound buffer.

`ack_limit.max`:::
Maximum number of agents that can call the Ack API concurrently. It allows the
user to avoid overloading the {fleet-server} from Ack API calls.

`ack_limit.interval`:::
How often an acknowledgment (ACK) is sent. Default value of 10ms enables 100
ACKs per second to be sent.

`ack_limit.burst`:::
Burst of ACKs to accommodate (default of 20) before falling back to the rate
defined in `interval`.

`enroll_limit.max`:::
Maximum number of agents that can call the Enroll API concurrently. This setting
allows the user to avoid overloading the {fleet-server} from Enrollment API
calls.

`enroll_limit.interval`:::
Interval between processing enrollment request. Enrollment is both CPU and RAM
intensive, so the number of enrollment requests needs to be limited for overall
system health. Default value of 100ms allows 10 enrollments per second.

`enroll_limit.burst`:::
Burst of enrollments to accept before falling back to the rate defined by
`interval`.

[discrete]
[[scaling-recommendations]]
=== Scaling recommendations

The following tables provide resource requirements and scaling guidelines based
on the number of agents required by your deployment:

* <<resource-requirements-by-number-agents>>
* <<recommend-settings-scaling-agents-a>>
* <<recommend-settings-scaling-agents-b>>

// Nima: Are these guidelines all cloud-specific? What about on prem/self-managed?

// Note: I don't like how the spanned rows under vCPU look. Do you think it's OK
// or should I just repeat the values?

// Nima: I'm looking at  elastic cloud, and the drop-down list of options that
// I see does not match these settings. Does this table need to be updated to
// show the new values?

[discrete]
[[resource-requirements-by-number-agents]]
==== Resource requirements by number of agents
|===
| Number of Agents | Memory      | vCPU           | {es} Cluster size

| 50               | 512MB    .5+| Up to 2.5 vCPU | 480GB disk \| 16GB RAM \| up to 5 vCPU
| 5,000            | 1GB                          | 960GB disk \| 32GB RAM \| 5 vCPU
| 7,500            | 2GB                          | 1.88TB disk \| 64GB RAM \| 9.8 vCPU
| 10,000           | 4GB                          | 3.75TB disk \| 128GB RAM \| 19.8 vCPU
| 12,500           | 8G                           | 7.5TB disk \| 256GB RAM \| 39.4 vCPU
| 30,000           | 16GB     .2+| 2.5 vCPU       | 7.5TB disk \| 256GB RAM \| 39.4 vCPU
| 50,000           | 32GB                         | 11.25TB disk \| 384GB RAM \|59.2 vCPU
|===

// Nima: I tried multiple iterations of this table (and the next) and none were
// great. Having one table with all these values was too much because it created
// a scroll bar at the bottom, and users could not see all of the columns at
// the top without scrolling. Figured two tables was better, but let's discuss.

[discrete]
[[recommend-settings-scaling-agents-a]]
==== Recommended settings for 50 to 10,000 agents
|===
|                      | *50*    | *5,000*  | *7,500*  | *10,000*
| *Max connections*    | 100     | 7,000    | 10,000   | 20,000
5+s| Cache settings
| `num_counters`      | 2000    | 20000    | 40000    | 80000
| `max_cost`          | 2097152 | 20971520 | 50971520 | 104857600
5+s| Server limits
| `policy_throttle`   | 200ms   | 50ms     | 10ms     | 5ms
5+| `checkin_limit:`
>| `interval`          | 50ms    | 5ms      | 2ms      | 1ms
>| `burst`             | 25      | 500      | 1000     | 2000
>| `max`               | 100     | 5001     | 7501     | 10001
5+| `artifact_limit:`
>| `interval`          | 100ms   | 5ms      | 2ms      | 1ms
>| `burst`             | 10      | 500      | 1000     | 2000
>| `max`               |1 0      | 1000     | 2000     | 4000
5+| `ack_limit:`
>| `interval`          | 10ms    | 4ms      | 2ms      | 1ms
>| `burst`             | 20      | 500      | 1000     | 2000
>| `max`               | 20      | 1000     | 2000     | 4000
5+| `enroll_limit:`
>| `interval`          | 100ms   | 20ms     | 10ms     | 10ms
>| `burst`             | 5       | 50       | 100      | 100
>| `max`               | 10      | 100      | 200      | 200
5+s| Server runtime settings
| `gc_percent`         | 20      | 20       | 20       | 20
|===

[discrete]
[[recommend-settings-scaling-agents-b]]
==== Recommended settings for 12,500 to 50,000 agents

|===
|                      | *12,500*  | *30,000*  | *50,000*
| *Max connections*    | 32,000    | 32,000    | 32,000
4+s| Cache settings
| `num_counters`       | 160000    | 160000    | 320000
| `max_cost`           | 209715200 | 209715200 | 209715200
4+s| Server limits
| `policy_throttle`    | 5ms       | 2ms       | 5ms
4+| `checkin_limit:`
>| `interval`          | 500us     | 500us     | 500us
>| `burst`             | 4000      | 4000      | 4000
>| `max`               | 12501     | 15001     | 25001
4+| `artifact_limit:`
>| `interval`          | 500us     | 500us     | 500us
>| `burst`             | 4000      | 4000      | 4000
>| `max`               | 8000      | 8000      | 8000
4+| `ack_limit:`
>| `interval`          | 500us     | 500us     | 500us
>| `burst`             | 4000      | 4000      | 4000
>| `max`               | 8000      | 8000      | 8000
4+| `enroll_limit:`
>| `interval`          | 10ms      | 10ms      | 10ms
>| `burst`             | 100       | 100       | 100 
>| `max`               | 200       | 200       | 200
4+s| Server runtime settings
| `gc_percent`         | 20        | 20        | 20
|===

[discrete]
[[fleet-server-monitoring]]
== {fleet-server} monitoring

//Suggestion: Talk about the metrics and logs that {fleet-server} provides, how
//users can enable and see them, how to use them to determine when to scale up
//{fleet-server}.

Monitoring {fleet-server} is key since the operation of the {fleet-server} is
paramount to the health of the deployed agents and the services they offer. When
{fleet-server} is not operating correctly, it may lead to delayed check-ins,
status information, and updates for the agents it manages. The monitoring data
will tell you when to add capacity for {fleet-server}, and provide error logs
and information to troubleshoot other issues.

To enable monitoring for {fleet-server}, turn on agent monitoring in the agent
policy. For self-managed clusters, monitoring is on by default when you create a
new agent policy or use the existing Default {fleet-server} agent policy.
However, it is off by default in the {ecloud} agent policy because monitoring
requires additional RAM.

To turn on {fleet-server} monitoring in the agent policy:

. In {fleet}, go to *Agent Policies* and click on the *{ecloud} agent policy*.
+
[role="screenshot"]
image::images/fleet-policy-page.png[Fleet Policy Page]

. Click the *Settings* tab and notice that Agent monitoring is
off by default.

. Under *Agent monitoring*, select *Collect agent logs* and
*Collect agent metrics*.
+
--
[role="screenshot"]
image::images/elastic-cloud-agent-policy-page.png[{ecloud} Policy Page]

The agent will now be able to collect logs and metrics from the {fleet-server}.

NOTE: The {fleet-server} is deployed as yet another agent in the system.
--

. Next, set the *Default namespace*.
+
Setting the default namespace lets you segregate {fleet-server} monitoring data
from other collected data. This makes it easier to search and visualize the
monitoring data. By default the monitoring data is sent to the *default*
namespace.

. To confirm your change, click *Save changes*.

To see the metrics collected for {fleet-server}, go to *Analytics > Discover*.

In the following example, `fleetserver` was configured as the namespace, and
you can see the metrics collected:

[role="screenshot"]
image::images/dashboard-with-namespace-showing.png[Namespace]

[role="screenshot"]
image::images/datastream-namespace.png[Datastream]

In {kib}, go to *Analytics > Dashboard* and search for the predefined dashboard
called *[Elastic Agent] Agent metrics*. Choose this dashboard, and run a query
based on the `fleetserver` namespace.

The following dashboard shows data for the query `data_stream.namespace:
"fleetserver"`. In this example, you can observe CPU and memory usage as a
metric and then resize the {fleet-server}, if necessary.

[role="screenshot"]
image::images/dashboard-datastream.png[Dashboard Datastream]

// Nima: These steps work, but I wonder how this is different from what you see
//in the [Elastic Agent] Agent metrics dashboard just by hiding all the metric
//except fleet_server.
